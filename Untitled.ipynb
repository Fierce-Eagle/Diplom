{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7339b99-bfe4-4f0d-aa1f-807f61091b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# чтобы предупреждения глаза не мазолили\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from my_dataset import create_dataset\n",
    "from model import Perceptron, Regression\n",
    "from train import train_model, test_model, train_regression\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3256ba50-28e0-4cbb-82fe-70235ba88ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2034581d-2393-46a2-938a-c62bfac08bbe",
   "metadata": {},
   "source": [
    "## Гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d13ef9-7dd8-4317-b0b1-756a75e0fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = \"dataset/\"\n",
    "NUM_EPOCH = 100\n",
    "SPECTRUM_SIZE = 300\n",
    "NUM_CLASSES = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b57d23-5c44-4603-8c00-452305e346c0",
   "metadata": {},
   "source": [
    "## Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f558ce0-21b2-4fe3-999d-4d994da992c7",
   "metadata": {},
   "source": [
    "### Создание датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2571926-fbac-4701-9a2d-8007cfd15c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/40/нут40_зерно8.txt\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf1 in position 261: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dataset, valid_dataset, test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATASET_DIR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mspectrum_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSPECTRUM_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43msmoothing_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                            \u001b[49m\u001b[43mshow_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Diplom/my_dataset.py:48\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[0;34m(dir_name, signal_start_frame_size_to_read, signal_frame_size_to_read, time_for_frame, frame_stride_percent, smoothing_window_size, spectrum_length, train_size, batch_size, is_regression_dataset, show_info)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(filename)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# считывание сигналов\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m signal_1, signal_2, signal_3, freqence \u001b[38;5;241m=\u001b[39m \u001b[43mload_info_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# обработка сигналов\u001b[39;00m\n\u001b[1;32m     51\u001b[0m signal_1, signal_2, signal_3 \u001b[38;5;241m=\u001b[39m cut_empty_frames_in_signals(signal_1, signal_2, signal_3)\n",
      "File \u001b[0;32m~/Diplom/signal_processing.py:17\u001b[0m, in \u001b[0;36mload_info_from_file\u001b[0;34m(filename, is_show_info)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m7\u001b[39m):  \u001b[38;5;66;03m# скип ненужных строк\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m         line \u001b[38;5;241m=\u001b[39m \u001b[43mfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(line)\n\u001b[1;32m     20\u001b[0m     line \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadline()\n",
      "File \u001b[0;32m/usr/lib/python3.10/codecs.py:322\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m+\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[0;32m--> 322\u001b[0m     (result, consumed) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer \u001b[38;5;241m=\u001b[39m data[consumed:]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf1 in position 261: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "train_dataset, valid_dataset, test_dataset = create_dataset(dir_name=DATASET_DIR,\n",
    "                                                            spectrum_length=SPECTRUM_SIZE, \n",
    "                                                            smoothing_window_size=10, \n",
    "                                                            show_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f02bab-2a8a-42b5-87c9-34a586f4ac57",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36788093-e7ac-4945-a092-92714669fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model = Perceptron(SPECTRUM_SIZE * 6, NUM_CLASSES).to(device)\n",
    "\n",
    "loss_history, best_model = train_model(train_dataset, valid_dataset, classification_model, epochs=NUM_EPOCH, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66741a84-fbf1-4794-acb0-05ca73b30504",
   "metadata": {},
   "source": [
    "#### Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a97ae10-990f-4c8b-84ed-0bcf2fd36fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('График потерь',fontsize=15)\n",
    "plt.xlabel('Эпохи',fontsize=12)\n",
    "plt.ylabel('Потери',fontsize=12)\n",
    "plt.plot(loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f8a10a-0d6c-4005-b30c-13632034abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = test_model(model=best_model, loader_test=test_dataset, device=device)\n",
    "\n",
    "y_true_test = []\n",
    "for _, y in test_dataset:\n",
    "    y_true_test += [p.item() for p in y]\n",
    "\n",
    "y_true_test = np.array(y_true_test)\n",
    "\n",
    "result_total = metrics.f1_score(y_true_test, y_pred_test, average='micro')\n",
    "class_results = metrics.f1_score(y_true_test, y_pred_test, average=None)\n",
    "\n",
    "print(\"Оценка качества F1 (общая):\", result_total)\n",
    "print()\n",
    "print(\"Оценка качества F1 по классам:\")\n",
    "for i, class_result in enumerate(class_results):\n",
    "    print(f\"Оценка качества F1 ({i}):\", class_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf0e62-b082-4914-ac78-a4168481690f",
   "metadata": {},
   "source": [
    "## Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f66ded-7ac6-4160-a87f-ac733e3def9b",
   "metadata": {},
   "source": [
    "### Создание датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea2198-6ebe-4f73-93fa-ade47f4a3f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_reg, valid_dataset_reg, test_dataset_reg = create_dataset(dir_name=DATASET_DIR, spectrum_length=SPECTRUM_SIZE, \n",
    "                                                                        is_regression_dataset=True, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fa4b18-8b04-4732-a871-bf73651f7fce",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93fa4b-a2c7-4277-b497-c1b51d458c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Создание модели\n",
    "model = LinearRegression()\n",
    "\n",
    "# Обучение модели на обучающем наборе\n",
    "model = model.fit(train_dataset_reg.dataset[:][\"data\"], train_dataset_reg.dataset[:][\"label\"])\n",
    "\n",
    "test_predictions = model.predict(test_dataset_reg.dataset[\"data\"])\n",
    "\n",
    "# Расчет MAE\n",
    "mae = mean_absolute_error(test_dataset_reg.dataset[\"label\"], test_predictions)\n",
    "\n",
    "print(f\"Средняя абсолютная ошибка (MAE): {mae:.2f}\")\n",
    "# print(model.coef_)\n",
    "\n",
    "#regression_model = Regression(SPECTRUM_SIZE * 6, 7).to(device)\n",
    "#criterion_reg = nn.MSELoss()\n",
    "\n",
    "#loss_history_reg, best_model_reg = train_regression(train_dataset_reg, valid_dataset_reg, regression_model, epochs=2000, device=device, \n",
    "#                                         criterion=criterion_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6711d067-7fb0-4a4b-8b7f-e72d01adc9e8",
   "metadata": {},
   "source": [
    "#### Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fe09f8-bddc-4e9a-9cd4-ce235f7d66f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
